<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Deep Flow-Guided Video Inpainting</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="Video-Inpainting.&gt;
&lt;meta name=" keywords"="">

<!-- Fonts and stuff -->
<link href="./video-inpainting/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./video-inpainting/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./video-inpainting/iconize.css">
<script type="text/javascript" async="" src="./video-inpainting/ga.js.download"></script><script async="" src="./video-inpainting/prettify.js.download"></script>

<script type="text/javascript">
            
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-22940424-1']);
            _gaq.push(['_trackPageview']);
            
            (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
            
</script>

</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1>Deep Flow-Guided Video Inpainting</h1>

	<div class="authors">
	  <a href="https://nbei.github.io/">Rui Xu<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://scholar.google.com.hk/citations?user=udZam0oAAAAJ&hl=zh-CN">Xiaoxiao Li<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://personal.ie.cuhk.edu.hk/~ccloy/">Chen Change Loy<sup>2</sup></a>
	</div>

	<div class="affiliations">
	  <sup>1</sup> <a href="http://mmlab.ie.cuhk.edu.hk/" target="_blank">CUHK - SenseTime Joint Lab, The Chinese University of Hong Kong</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>
	  <sup>2</sup> <a>Nanyang Technological University, Singapore</a>
	</div>

	<div class="venue"></div>
  </div>

    
  <div class="section demo">
		
		<br>
		<center><iframe width="840" height="480"
			src="https://www.youtube.com/embed/LIJPUsrwx5E">
			</iframe></center>
		<br>
	</div>

  <div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
			Video inpainting, which aims at filling in missing regions of  a video, 
			remains challenging due to the difficulty of preserving the precise spatial 
			and temporal coherence of video contents. In this work we propose a novel 
			flow-guided video inpainting approach. Rather than filling in the RGB pixels 
			of each frame directly, we consider video inpainting as a pixel propagation 
			problem. We first synthesize a spatially and temporally coherent optical flow 
			field across video frames using a newly designed Deep Flow Completion network. 
			Then the synthesized flow field is used to guide the propagation of pixels to 
			fill up the missing regions in the video. Specifically, the Deep Flow Completion 
			network follows a coarse-to-fine refinement to complete the flow fields, while 
			their quality is further improved by hard flow example mining. Following the 
			guide of the completed flow, the missing video regions can be filled up precisely. 
			Our method is evaluated on DAVIS and YouTube-VOS datasets qualitatively and 
			quantitatively, achieving the state-of-the-art performance in terms of 
			inpainting quality and speed. 

	</p>
      </div>
      
	<div class="section framework">
	<h2>Framework</h2>
	<br>
	<center><img src="./video-inpainting/framework.png" border="0" width="95%"></center>
	<br>
	<p>
			Our framework contains two steps, the first step is to complete the missing flow while the second step is to propagate pixels with the guidance of completed flow fields.
			In the first step, a Deep Flow Completion Network (DFC-Net) is proposed for coarse-to-fine flow completion.
			
			DFC-Net consists of three similar subnetworks named as DFC-S.
			
			The first subnetwork estimates the flow in a relatively coarse scale and feeds them into the second and third subnetwork for further refinement.
			
			In the second step, after the flow is obtained, most of the missing regions can be filled up by pixels in known regions through a flow-guided propagation from different frames.
			
			A conventional image inpainting network is finally employed to complete the remaining regions that are not seen in the entire video.
			
			Thanks to the high-quality estimated flow in the first step, we can easily propagate these image inpainting results to the entire video sequence.
	</p>
    </div>

		<div class="section visualization">
			<h2>Visualization</h2>
			<br>
				<center><img src="./video-inpainting/final.png" border="0" width="100%"></center>
			<p>
			Results of our flow-guided video inpainting approach. For each input sequence (odd row), 
			we show representative frames with mask of missing region overlay. We show the inpainting 
			results in even rows.<b> (Best viewed with zoom-in.)</b>
			</p>
			
			<center><img src="./video-inpainting/visual-compare.png" border="0" width="100%"></center>
			<p>
			<center>Comparision with Huang et al.</center>
			</p>
		</div>
	  
<div class="section materials">
	<h2>Materials</h2>
	<center>
	  <ul>

          <li class="grid">
	      <div class="griditem">
		<a href="https://arxiv.org" target="_blank" class="imageLink"><img src="./video-inpainting/paper.png" border="0" width="50%"></a><br>
		  <a href="https://arxiv.org" target="_blank">Paper (to be updated)</a>
		</div>
	      </li>
		  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		  
		  <li class="grid">
	      <div class="griditem">
		<a><img src="./video-inpainting/code.png"></a><br>
		  <a>Codes (coming soon)</a>
		</div>
	      </li>
	  
	    </ul>
	    </center>
	    </div>
	    
<br>

<div class="section citation">
	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@Article{xu2019deepflow,
 author = {Xu, Rui and Li, Xiaoxiao and Zhou, Bolei and Loy, Chen Change},
 title = {Deep Flow-Guided Video Inpainting},
 journal = {arXiv preprint (to be updated)},
 year = {2019} 
}</pre>
	  </div>
      </div>

</div></div></body></html>